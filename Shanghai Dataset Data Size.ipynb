{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "477356b2",
   "metadata": {},
   "source": [
    "### Importing the necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5336792",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import h5py\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6470e90",
   "metadata": {},
   "source": [
    "### Data Size for all the Shanghai Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "6758423c",
   "metadata": {},
   "outputs": [],
   "source": [
    "part_A_train = os.path.join(os.getcwd(),'ShanghaiTech\\\\part_A\\\\train_data\\\\images')\n",
    "part_A_test = os.path.join(os.getcwd(),'ShanghaiTech\\\\part_A\\\\test_data\\\\images')\n",
    "part_B_train = os.path.join(os.getcwd(),'ShanghaiTech\\\\part_B\\\\train_data\\\\images')\n",
    "part_B_test = os.path.join(os.getcwd(),'ShanghaiTech\\\\part_B\\\\test_data\\\\images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "ceaf1987",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "part_A_train_images = glob.glob(os.path.join(part_A_train,'*.jpg'))\n",
    "len(part_A_train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "173e9ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shanghai Part A train -- total size 300\n",
      "Shanghai Part A test -- total size 182\n",
      "Shanghai Part B train -- total size 400\n",
      "Shanghai Part B test -- total size 316\n",
      "Total people counting images = 1198\n"
     ]
    }
   ],
   "source": [
    "part_A_train_images = glob.glob(os.path.join(part_A_train,'*.jpg'))\n",
    "part_A_test_images = glob.glob(os.path.join(part_A_test,'*.jpg'))\n",
    "part_B_train_images = glob.glob(os.path.join(part_B_train,'*.jpg'))\n",
    "part_B_test_images = glob.glob(os.path.join(part_B_test,'*.jpg'))\n",
    "print(f'Shanghai Part A train -- total size {len(part_A_train_images)}')\n",
    "print(f'Shanghai Part A test -- total size {len(part_A_test_images)}')\n",
    "print(f'Shanghai Part B train -- total size {len(part_B_train_images)}')\n",
    "print(f'Shanghai Part B test -- total size {len(part_B_test_images)}')\n",
    "print(f'Total people counting images = {len(part_A_train_images)+len(part_A_test_images)+len(part_B_train_images)+len(part_B_test_images)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e5b5b8",
   "metadata": {},
   "source": [
    "### Image Sizes for all the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "287a683a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def images_size(list_of_images_paths, list_names):\n",
    "    writer = pd.ExcelWriter('ShanghaiTech Data.xlsx', engine='xlsxwriter')\n",
    "    \n",
    "    for index, (path, name) in enumerate(zip(list_of_images_paths, list_names), 1):\n",
    "        images_data = {\"Sno\": [],  # Add a Sno column\n",
    "                       \"Image_Name\": [],\n",
    "                       \"Width\": [],\n",
    "                       \"Height\": [],\n",
    "                       \"Channels\": [],\n",
    "                       \"Channel_Name\": []}\n",
    "        \n",
    "        def extract_number(path):\n",
    "            \"\"\"Extracts the number from the image filename.\"\"\"\n",
    "            filename = path.split('\\\\')[-1]\n",
    "            return int(filename.split('_')[1].split('.')[0])\n",
    "    \n",
    "        image_paths = sorted(path,key=extract_number)\n",
    "\n",
    "        sno = 1  # Initialize sno counter\n",
    "        \n",
    "        for image_path in image_paths:\n",
    "            try:\n",
    "                image_name = os.path.splitext(os.path.basename(image_path))[0]\n",
    "                image_array = plt.imread(image_path)\n",
    "\n",
    "                if len(image_array.shape) == 3:\n",
    "                    height, width, channels = image_array.shape\n",
    "                    channel_name = 'RGB'\n",
    "                else:\n",
    "                    height, width = image_array.shape\n",
    "                    channels = 1\n",
    "                    channel_name = 'Gray'\n",
    "\n",
    "                images_data['Sno'].append(sno)  # Add sno value\n",
    "                sno += 1  # Increment sno counter\n",
    "                images_data['Height'].append(height)\n",
    "                images_data['Width'].append(width)\n",
    "                images_data['Channel_Name'].append(channel_name)\n",
    "                images_data['Channels'].append(channels)\n",
    "                images_data['Image_Name'].append(image_name)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing image: {image_path}, Exception: {e}\")\n",
    "\n",
    "        dataframe = pd.DataFrame(images_data)\n",
    "        dataframe.to_excel(writer, sheet_name=f'{name}', index=False)\n",
    "    \n",
    "    writer.close()  # Save the Excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "c6e268c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_names = [\"part_A_train_images\",\"part_A_test_images\",\"part_B_train_images\",\"part_B_test_images\"]\n",
    "list_of_images_path = [part_A_train_images,part_A_test_images,part_B_train_images,part_B_test_images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "0fb8572a",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_size(list_of_images_path,list_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "278ea851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMG_1\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "\n",
    "# file_path = 'C:\\\\Users\\\\farheen.syed_iprotec\\\\Desktop\\\\python\\\\ShanghaiTech/part_A/train_data/images\\\\IMG_1.jpg'\n",
    "\n",
    "# # Get the image name from the file path\n",
    "# image_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "\n",
    "# print(image_name)  # This will print 'IMG_1.jpg'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "199d41c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def images_size(list_of_images_paths, list_names):\n",
    "#     all_shapes = []\n",
    "\n",
    "#     for index, path in enumerate(list_of_images_paths, 0):\n",
    "#         shapes = []\n",
    "\n",
    "#         for image_path in path:\n",
    "#             try:\n",
    "#                 image_name = os.path.splitext(os.path.basename(image_path))[0]\n",
    "#                 image_array = plt.imread(image_path)\n",
    "\n",
    "#                 if len(image_array.shape) == 3:\n",
    "#                     height, width, channels = image_array.shape\n",
    "#                 else:\n",
    "#                     height, width = image_array.shape\n",
    "#                     channels = 1\n",
    "\n",
    "#                 shape_info = {\n",
    "#                     \"Image_Name\": image_name,\n",
    "#                     \"Height\": height,\n",
    "#                     \"Width\": width,\n",
    "#                     \"Channels\": channels,\n",
    "#                     \"Channel_Name\": \"RGB\" if channels == 3 else \"Gray\"\n",
    "#                 }\n",
    "#                 shapes.append(shape_info)\n",
    "\n",
    "#             except Exception as e:\n",
    "#                 print(f\"Error processing image: {image_path}, Exception: {e}\")\n",
    "\n",
    "#         all_shapes.extend(shapes)\n",
    "\n",
    "#         # Write the shape information to a file for each list of images\n",
    "#         with open(f'{list_names[index]}_shapes.txt', 'w') as f:\n",
    "#             for shape_info in shapes:\n",
    "#                 f.write(f\"{shape_info}\\n\")\n",
    "\n",
    "#     # Write the combined shape information to a single file\n",
    "#     with open('Final_Shapes.txt', 'w') as f:\n",
    "#         for shape_info in all_shapes:\n",
    "#             f.write(f\"{shape_info}\\n\")\n",
    "\n",
    "# # Example usage:\n",
    "# # list_names = [\"part_A_train_images\", \"part_A_test_images\", \"part_B_train\", \"part_B_test_images\"]\n",
    "# # list_of_images_path = [part_A_train_images, part_A_test_images, part_B_train, part_B_test_images]\n",
    "# # images_size(list_of_images_path, list_names)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
